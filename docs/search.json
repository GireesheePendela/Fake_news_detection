[
  {
    "objectID": "notebooks/vectorization.html",
    "href": "notebooks/vectorization.html",
    "title": "TF-IDF Vectorization",
    "section": "",
    "text": "df = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\Projects\\Fake_news_detection\\data\\cleaned_news.csv\")\nprint(df.columns)  # Confirm clean_text is present\n\nIndex(['title', 'text', 'subject', 'date', 'label', 'clean_text'], dtype='object')\n\n\n\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\n# Load cleaned data\ndf = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\Projects\\Fake_news_detection\\data\\cleaned_news.csv\")\n\n# Drop rows with missing clean_text\ndf = df.dropna(subset=['clean_text'])\n\n# Initialize TF-IDF Vectorizer\nvectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n\n# Fit and transform the 'clean_text' column\nX = vectorizer.fit_transform(df['clean_text'])\n\n# Target variable\ny = df['label']\n\n# Train-test split (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Check dimensions\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\n\nX_train shape: (35412, 218495)\nX_test shape: (8854, 218495)\n\n\n\nprint(df['clean_text'].isna().sum())  # Count NaNs\n\n0"
  },
  {
    "objectID": "notebooks/training_model2.html",
    "href": "notebooks/training_model2.html",
    "title": "Train model using Multinomial Naive Bayes",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, classification_report\n)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n#  Load the cleaned dataset\ndf = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\Projects\\Fake_news_detection\\data\\cleaned_news.csv\")\ndf = df.dropna(subset=['clean_text'])\n\n#  TF-IDF Vectorization\nvectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\nX = vectorizer.fit_transform(df['clean_text'])\ny = df['label']\n\n#  Train-test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n#  Logistic Regression\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n#  Evaluation Metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(f\" Accuracy:  {accuracy:.4f}\")\nprint(f\" Precision: {precision:.4f}\")\nprint(f\" Recall:    {recall:.4f}\")\nprint(f\" F1 Score:  {f1:.4f}\")\n\n Accuracy:  0.9845\n Precision: 0.9868\n Recall:    0.9815\n F1 Score:  0.9841\n\n\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Train the model\nnb_model = MultinomialNB()\nnb_model.fit(X_train, y_train)\n\n# Predict\nnb_pred = nb_model.predict(X_test)\n\n# Evaluate\nnb_accuracy = accuracy_score(y_test, nb_pred)\nnb_precision = precision_score(y_test, nb_pred)\nnb_recall = recall_score(y_test, nb_pred)\nnb_f1 = f1_score(y_test, nb_pred)\n\nprint(\" Multinomial Naive Bayes Evaluation:\")\nprint(f\"Accuracy:  {nb_accuracy:.4f}\")\nprint(f\"Precision: {nb_precision:.4f}\")\nprint(f\"Recall:    {nb_recall:.4f}\")\nprint(f\"F1 Score:  {nb_f1:.4f}\")\n\n Multinomial Naive Bayes Evaluation:\nAccuracy:  0.9381\nPrecision: 0.9317\nRecall:    0.9425\nF1 Score:  0.9371\n\n\nconfusion_matrix\n\nnb_cm = confusion_matrix(y_test, nb_pred)\nlabels = ['Fake', 'Real']\n\nplt.figure(figsize=(6, 5))\nax = sns.heatmap(nb_cm, annot=False, cmap='Purples', xticklabels=labels, yticklabels=labels, cbar=False)\n\nfor i in range(nb_cm.shape[0]):\n    for j in range(nb_cm.shape[1]):\n        ax.text(j + 0.5, i + 0.5, nb_cm[i, j], ha='center', va='center', color='black', fontsize=14)\n\nax.set_title(\"Confusion Matrix - Naive Bayes\", fontsize=14)\nax.set_xlabel(\"Predicted Label\", fontsize=12)\nax.set_ylabel(\"Actual Label\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nROC curve\n\nfrom sklearn.metrics import roc_curve, auc\n\n# Predict probabilities\ny_proba = nb_model.predict_proba(X_test)[:, 1]\n\n# ROC values\nfpr, tpr, thresholds = roc_curve(y_test, y_proba)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC\nplt.figure(figsize=(6, 5))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\nplt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nplt.legend(loc=\"lower right\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWord Cloud\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Create separate text blobs for each class\nfake_text = \" \".join(df[df['label'] == 0]['clean_text'])\nreal_text = \" \".join(df[df['label'] == 1]['clean_text'])\n\n#  Word cloud for fake news (red tint)\nwc_fake = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(fake_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wc_fake, interpolation='bilinear')\nplt.axis('off')\nplt.title(\" Word Cloud - Fake News\", fontsize=16)\nplt.tight_layout()\nplt.show()\n\n#  Word cloud for real news (green tint)\nwc_real = WordCloud(width=800, height=400, background_color='white', colormap='Greens').generate(real_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wc_real, interpolation='bilinear')\nplt.axis('off')\nplt.title(\" Word Cloud - Real News\", fontsize=16)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/load_and_combine_data.html",
    "href": "notebooks/load_and_combine_data.html",
    "title": "Load and Combing the Data",
    "section": "",
    "text": "import pandas as pd\n\n# Load the datasets\nfake_df = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\projects\\fake_news_detection\\data\\Fake.csv\")\nreal_df = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\projects\\fake_news_detection\\data\\True.csv\")\n\n# Add labels\nfake_df['label'] = 0  # 0 = Fake\nreal_df['label'] = 1  # 1 = Real\n\n# Combine the two datasets\ndf = pd.concat([fake_df, real_df])\n\n# Shuffle the rows\ndf = df.sample(frac=1).reset_index(drop=True)\n\n# Quick peek\nprint(df.head())\nprint(df['label'].value_counts())\n\n                                               title  \\\n0  Justices hostile to Virginia Republicans in bl...   \n1  Trump to detour from campaign to visit Scotlan...   \n2   Two Days Ago, Trump Asked Russia To Hack Clin...   \n3  SHOCKING: Why Our Fed Government Will Grant ‚ÄúD...   \n4   Hillary‚Äôs Message To Former Miss Universe Cal...   \n\n                                                text       subject  \\\n0  WASHINGTON (Reuters) - Supreme Court justices ...  politicsNews   \n1  WASHINGTON (Reuters) - Facing slumping poll nu...  politicsNews   \n2  It s time the American people wake up to the d...          News   \n3  If we didn t know better, we d almost believe ...     left-news   \n4  Miss Universe 1996 Alicia Machado is now an Am...          News   \n\n              date  label  \n0  March 21, 2016       1  \n1   June 22, 2016       1  \n2    July 29, 2016      0  \n3      Apr 7, 2015      0  \n4     May 20, 2016      0  \nlabel\n0    23481\n1    21417\nName: count, dtype: int64\n\n\n\n# Save combined data to a new CSV file for later use\ndf.to_csv(r\"C:\\Users\\hp\\Desktop\\Projects\\Fake_news_detection\\data\\combined_news.csv\", index=False)"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Dataset",
    "section": "",
    "text": "The dataset used in this project comes from Kaggle: Fake and Real News Dataset, and consists of two separate CSV files:\n\nFake.csv ‚Äî Contains news articles that are labeled as fake\nTrue.csv ‚Äî Contains news articles that are labeled as real\n\nEach file includes the following columns: - title: The headline of the news article - text: The body/content of the article - subject: Topic category (e.g., politics, world news) - date: Publication date"
  },
  {
    "objectID": "data.html#combining-the-dataset",
    "href": "data.html#combining-the-dataset",
    "title": "Dataset",
    "section": "üîó Combining the Dataset",
    "text": "üîó Combining the Dataset\nTo train a supervised machine learning model, we need a single labeled dataset. So we:\n\nAssigned a new column called label:\n\n0 for fake articles\n1 for real articles\n\nUsed pandas.concat() to combine both datasets into one DataFrame\nShuffled the rows to randomize the ordering\nSaved the result as combined_news.csv\n\nThis ensures a balanced and properly labeled dataset for training and testing."
  },
  {
    "objectID": "data.html#text-cleaning-and-preprocessing",
    "href": "data.html#text-cleaning-and-preprocessing",
    "title": "Dataset",
    "section": "üßπ Text Cleaning and Preprocessing",
    "text": "üßπ Text Cleaning and Preprocessing\nTo make the raw news content usable for modeling, we applied several text preprocessing steps on the text column:\n\nLowercasing all words\nRemoving punctuation and special characters\nTokenizing into words\nRemoving stopwords (e.g., ‚Äúthe‚Äù, ‚Äúand‚Äù, ‚Äúis‚Äù)\nLemmatizing words (e.g., ‚Äúrunning‚Äù ‚Üí ‚Äúrun‚Äù)\n\nThe cleaned text was stored in a new column called clean_text, and the final preprocessed dataset was saved as cleaned_news.csv.\n\nThese steps help reduce noise and ensure that the model learns from meaningful textual features."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fake News Detection",
    "section": "",
    "text": "This project aims to detect whether a given news article is real or fake using Natural Language Processing (NLP) and supervised machine learning models.\nWe use a labeled dataset of real and fake news articles to: - Preprocess and clean the text - Convert it into numerical features using TF-IDF Vectorization - Train models such as Logistic Regression and Multinomial Naive Bayes - Evaluate performance using standard classification metrics - Visualize insights like confusion matrices, word clouds, and top predictive words\n\n\nFake news can spread rapidly and influence public opinion. This project focuses on building a model that can automatically distinguish between fake and real news articles based on textual content.\n\n\n\n\nThe dataset consists of: - Fake.csv: News articles labeled as fake - True.csv: News articles labeled as real\nThe two datasets are combined and labeled (0 = fake, 1 = real), then cleaned and preprocessed for modeling.\n\n\n\n\n\nPython (Pandas, NumPy, Scikit-learn)\nNatural Language Toolkit (NLTK)\nMatplotlib, Seaborn\nWordCloud\nQuarto (for documentation and static site)"
  },
  {
    "objectID": "index.html#project-overview",
    "href": "index.html#project-overview",
    "title": "Fake News Detection",
    "section": "",
    "text": "This project aims to detect whether a given news article is real or fake using Natural Language Processing (NLP) and supervised machine learning models.\nWe use a labeled dataset of real and fake news articles to: - Preprocess and clean the text - Convert it into numerical features using TF-IDF Vectorization - Train models such as Logistic Regression and Multinomial Naive Bayes - Evaluate performance using standard classification metrics - Visualize insights like confusion matrices, word clouds, and top predictive words\n\n\nFake news can spread rapidly and influence public opinion. This project focuses on building a model that can automatically distinguish between fake and real news articles based on textual content.\n\n\n\n\nThe dataset consists of: - Fake.csv: News articles labeled as fake - True.csv: News articles labeled as real\nThe two datasets are combined and labeled (0 = fake, 1 = real), then cleaned and preprocessed for modeling.\n\n\n\n\n\nPython (Pandas, NumPy, Scikit-learn)\nNatural Language Toolkit (NLTK)\nMatplotlib, Seaborn\nWordCloud\nQuarto (for documentation and static site)"
  },
  {
    "objectID": "index.html#github-repository",
    "href": "index.html#github-repository",
    "title": "Fake News Detection",
    "section": "üìÅ GitHub Repository",
    "text": "üìÅ GitHub Repository\nüëâ View GitHub Repository"
  },
  {
    "objectID": "notebooks/preprocess_text.html",
    "href": "notebooks/preprocess_text.html",
    "title": "Preprocessing the data",
    "section": "",
    "text": "import pandas as pd\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n# Load the combined dataset\ndf = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\Projects\\Fake_news_detection\\data\\combined_news.csv\")\n\n\n\n# Download necessary NLTK resources (run once)\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')\n\n# Initialize stopwords and lemmatizer\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\n# Define text preprocessing function\ndef clean_text(text):\n    text = str(text).lower()                              # Lowercase\n    text = re.sub(r'[^\\w\\s]', '', text)                   # Remove punctuation\n    words = nltk.word_tokenize(text)                      # Tokenize\n    words = [w for w in words if w not in stop_words]     # Remove stopwords\n    words = [lemmatizer.lemmatize(w) for w in words]      # Lemmatize\n    return ' '.join(words).strip()                        # Join and remove extra spaces\n\n# Apply preprocessing to the 'text' column\ndf['clean_text'] = df['text'].apply(clean_text)\n\n# Preview results\nprint(df[['text', 'clean_text']].head())\n\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n\n\n                                                text  \\\n0  WASHINGTON (Reuters) - Supreme Court justices ...   \n1  WASHINGTON (Reuters) - Facing slumping poll nu...   \n2  It s time the American people wake up to the d...   \n3  If we didn t know better, we d almost believe ...   \n4  Miss Universe 1996 Alicia Machado is now an Am...   \n\n                                          clean_text  \n0  washington reuters supreme court justice monda...  \n1  washington reuters facing slumping poll number...  \n2  time american people wake danger treasonous na...  \n3  know better almost believe federal government ...  \n4  miss universe 1996 alicia machado american cit...  \n\n\n\n# Save the cleaned DataFrame to a new CSV\ndf.to_csv(r\"C:\\Users\\hp\\Desktop\\Projects\\Fake_news_detection\\data\\cleaned_news.csv\", index=False)"
  },
  {
    "objectID": "notebooks/training_model_1.html",
    "href": "notebooks/training_model_1.html",
    "title": "Train the Model using Logistic Regresiion",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, classification_report\n)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n#  Load the cleaned dataset\ndf = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\Projects\\Fake_news_detection\\data\\cleaned_news.csv\")\ndf = df.dropna(subset=['clean_text'])\n\n#  TF-IDF Vectorization\nvectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\nX = vectorizer.fit_transform(df['clean_text'])\ny = df['label']\n\n#  Train-test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n#  Logistic Regression\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n#  Evaluation Metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(f\" Accuracy:  {accuracy:.4f}\")\nprint(f\" Precision: {precision:.4f}\")\nprint(f\" Recall:    {recall:.4f}\")\nprint(f\" F1 Score:  {f1:.4f}\")\n\n Accuracy:  0.9845\n Precision: 0.9868\n Recall:    0.9815\n F1 Score:  0.9841\n\n\nConfusion Matrix\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n# Compute confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nlabels = ['Fake', 'Real']\n\n# Create heatmap\nplt.figure(figsize=(6, 5))\nax = sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=labels, yticklabels=labels, cbar=False)\n\n# Add manual annotations to all cells\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        text = f\"{cm[i, j]}\"\n        ax.text(j + 0.5, i + 0.5, text, ha='center', va='center', color='black', fontsize=14)\n\n# Set titles and labels\nax.set_xlabel(\"Predicted Label\", fontsize=12)\nax.set_ylabel(\"Actual Label\", fontsize=12)\nax.set_title(\" Confusion Matrix\", fontsize=14)\nax.tick_params(axis='both', labelsize=11)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nCorrelation Matrix\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Compute correlation matrix\ncorr_matrix = df[['label', 'text_length']].corr()\n\n# Create the heatmap\nplt.figure(figsize=(5, 4))\nax = sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', fmt='.2f', cbar=True)\n\n# Manually add text to all cells\nfor i in range(corr_matrix.shape[0]):\n    for j in range(corr_matrix.shape[1]):\n        text = f\"{corr_matrix.iloc[i, j]:.2f}\"\n        ax.text(j + 0.5, i + 0.5, text, ha='center', va='center', color='white', fontsize=12)\n\n# Fix axes\nax.set_xticklabels(corr_matrix.columns, rotation=0)\nax.set_yticklabels(corr_matrix.index, rotation=0)\nplt.title(\"Correlation Matrix\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTop Keywords\n\n# Get feature importance from logistic regression\nfeature_names = vectorizer.get_feature_names_out()\ncoefs = model.coef_[0]\n\n# Top 20 positive and negative words\ntop_real = np.argsort(coefs)[-20:]\ntop_fake = np.argsort(coefs)[:20]\n\nplt.figure(figsize=(10, 6))\nplt.barh(range(20), coefs[top_real], color='green')\nplt.yticks(range(20), feature_names[top_real])\nplt.title(\"Top 20 Words Predicting Real News\")\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(10, 6))\nplt.barh(range(20), coefs[top_fake], color='red')\nplt.yticks(range(20), feature_names[top_fake])\nplt.title(\"Top 20 Words Predicting Fake News\")\nplt.tight_layout()\nplt.show()"
  }
]